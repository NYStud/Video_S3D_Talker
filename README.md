# Video_S3D_Talker

## Building and Updating...

## Features of the project will be:

```
- A transformer based video captioning architecture on YouCook2, MSR-VTT and V2C dataset.

- 3D video features extracted from a largely pre-trained S3D models from HowTo100M dataset.

- Performance reproduced from the recent video representation learning work:
Sun, Chen, et al. "Contrastive bidirectional transformer for temporal representation learning

- Comparisons with other video captioning features like ResNet, or NCE finetuned S3D baselines.
```

Thanks ***Luowei Zhou*** for sharing his raw videos of [YouCook2 dataset](http://youcook2.eecs.umich.edu/), and  ***Antoine Miech, Jean-Baptiste Alayrac*** for their [HowTo100M pre-trained S3D models](https://github.com/antoine77340/S3D_HowTo100M).

## Things to do:
- [x] Upload training script on YC2 Dataset.   - Feb. 5th
- [ ] Release extracted video segment features of YC2 using S3D models.
- [ ] Evaluation script and performances.
- [ ] Baseline models on MSR-VTT and performances.
